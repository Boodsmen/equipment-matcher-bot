"""Handler for uploaded documents (DOCX, future PDF)."""

import os

from aiogram import Bot, Router
from aiogram.types import FSInputFile, Message

from config import settings
from database.crud import save_search_history
from services.docx_parser import extract_text_from_docx
from services.excel_generator import generate_report
from services.matcher import find_matching_models
from services.openai_service import process_document
from services.table_parser import parse_requirements_from_tables
from utils.logger import logger

router = Router()

TEMP_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), "temp_files")


@router.message(lambda m: m.document is not None)
async def handle_document(message: Message, bot: Bot) -> None:
    """Download and process an uploaded document."""
    doc = message.document
    file_name = doc.file_name or "unknown"
    user_id = message.from_user.id
    logger.info(f"Document received from {user_id}: {file_name} ({doc.file_size} bytes)")

    # PDF ‚Äî future support
    if file_name.lower().endswith(".pdf"):
        await message.answer(
            "–ü–æ–¥–¥–µ—Ä–∂–∫–∞ PDF –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ.\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ DOCX."
        )
        return

    # Only DOCX allowed
    if not file_name.lower().endswith(".docx"):
        await message.answer(
            "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ DOCX."
        )
        return

    # Check file size (20 MB limit)
    if doc.file_size and doc.file_size > 20 * 1024 * 1024:
        await message.answer("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å. 20 –ú–ë).")
        return

    status_msg = await message.answer("–§–∞–π–ª –ø–æ–ª—É—á–µ–Ω. –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑...")

    os.makedirs(TEMP_DIR, exist_ok=True)
    file_path = os.path.join(TEMP_DIR, f"{user_id}_{file_name}")

    try:
        # Download file
        file = await bot.get_file(doc.file_id)
        await bot.download_file(file.file_path, file_path)
        logger.info(f"File downloaded to {file_path}")

        # HYBRID APPROACH: Try table parser first, then AI fallback
        await status_msg.edit_text("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞...")

        # Strategy 1: Direct table parsing (fast, reliable for structured docs)
        logger.info("Attempting table-based parsing...")
        requirements = parse_requirements_from_tables(file_path)

        if requirements:
            items = requirements.get("items", [])
            logger.info(f"‚úì Table parser succeeded: {len(items)} items extracted")
            await status_msg.edit_text(
                f"‚úì –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n"
                f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–æ–∑–∏—Ü–∏–π: {len(items)}"
            )
        else:
            # Strategy 2: AI-based parsing (flexible for unstructured docs)
            logger.info("Table parser returned None, falling back to AI...")
            await status_msg.edit_text("–ò–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
            text = extract_text_from_docx(file_path)

            if not text.strip():
                await status_msg.edit_text("–î–æ–∫—É–º–µ–Ω—Ç –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞.")
                return

            # Process with OpenAI (Router -> Parser)
            await status_msg.edit_text(
                f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é AI ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)...\n"
                "–≠—Ç–∞–ø 1/2: –ü–æ–∏—Å–∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π..."
            )

            requirements = await process_document(text, "docx")
            items = requirements.get("items", [])

        if not items:
            await status_msg.edit_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏."
            )
            return

        # Format results summary
        summary_lines = [f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–æ–∑–∏—Ü–∏–π –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è: {len(items)}\n"]
        for i, item in enumerate(items, 1):
            name = item.get("item_name") or item.get("model_name") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
            category = item.get("category") or "‚Äî"
            specs_count = len(item.get("required_specs", {}))
            model = item.get("model_name")
            model_str = f" (–º–æ–¥–µ–ª—å: {model})" if model else ""
            summary_lines.append(f"{i}. {name}{model_str}\n   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {specs_count}")

        summary_text = "\n".join(summary_lines)

        # Stage 3: Match models with database
        await status_msg.edit_text(
            f"{summary_text}\n\n"
            "–≠—Ç–∞–ø 2/3: –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö..."
        )

        match_results = await find_matching_models(requirements)
        match_summary = match_results.get("summary", {})

        # Format match results
        result_lines = [
            f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:",
            f"–ù–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {match_summary.get('total_models_found', 0)}",
            f"–ò–¥–µ–∞–ª—å–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {match_summary.get('ideal_matches', 0)}",
            f"–ß–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {match_summary.get('partial_matches', 0)}",
        ]

        # Show top matches for each requirement
        for idx, result in enumerate(match_results.get("results", []), 1):
            req = result["requirement"]
            matches = result["matches"]
            ideal = matches.get("ideal", [])
            partial = matches.get("partial", [])

            req_name = req.get("item_name") or req.get("model_name") or f"–ü–æ–∑–∏—Ü–∏—è {idx}"

            if ideal:
                top = ideal[0]
                result_lines.append(
                    f"\n{idx}. {req_name}:\n"
                    f"   ‚úÖ {top['model_name']} ({top['source_file']}) ‚Äî 100%"
                )
            elif partial:
                top = partial[0]
                result_lines.append(
                    f"\n{idx}. {req_name}:\n"
                    f"   ‚ö†Ô∏è {top['model_name']} ({top['source_file']}) ‚Äî {top['match_percentage']}%"
                )
            else:
                result_lines.append(f"\n{idx}. {req_name}:\n   ‚ùå –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        match_text = "\n".join(result_lines)

        # Stage 4: Generate Excel report
        await status_msg.edit_text(
            f"{summary_text}\n{match_text}\n\n"
            "–≠—Ç–∞–ø 3/3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel –æ—Ç—á–µ—Ç–∞..."
        )

        excel_path = generate_report(
            requirements=requirements,
            match_results=match_results,
            output_dir=TEMP_DIR,
            threshold=settings.match_threshold,
            min_percentage=80.0,  # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º >= 80%
        )

        # Save search history (non-critical ‚Äî don't break main flow)
        try:
            await save_search_history(
                user_id=user_id,
                docx_filename=file_name,
                requirements=requirements,
                results_summary=match_summary,
            )
        except Exception as e:
            logger.error(f"Failed to save search history: {e}")

        # Send Excel file to user
        excel_file = FSInputFile(excel_path, filename=os.path.basename(excel_path))
        await message.answer_document(
            document=excel_file,
            caption=(
                f"–û—Ç—á–µ—Ç –≥–æ—Ç–æ–≤!\n\n"
                f"{summary_text}\n{match_text}\n\n"
                f"üìä –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ ‚Äî –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–Ω–æ–º Excel —Ñ–∞–π–ª–µ."
            ),
        )

        # Delete status message
        await status_msg.delete()

        logger.info(
            f"Document processed for user {user_id}: {len(items)} items, "
            f"{match_summary.get('total_models_found', 0)} models found"
        )

    except ValueError as e:
        logger.error(f"Document parsing error for user {user_id}: {e}")
        await status_msg.edit_text(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:\n{e}")
    except Exception as e:
        logger.error(f"Unexpected error processing document for user {user_id}: {e}", exc_info=True)
        await status_msg.edit_text(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
        )
    finally:
        # Cleanup temp files
        if os.path.exists(file_path):
            os.remove(file_path)
            logger.debug(f"Temp DOCX removed: {file_path}")

        # Cleanup Excel file (if generated)
        if "excel_path" in locals() and os.path.exists(excel_path):
            os.remove(excel_path)
            logger.debug(f"Temp Excel removed: {excel_path}")
